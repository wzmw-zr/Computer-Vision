# ProposalTargetCreator算法流程分析

ProposalTargetCreator在Fast RCNN Head中生成目标Proposal (给传递过来的RoIs分配ground truth bounding box)，结果用于计算Fast RCNN的分类和定位损失。



**超参数**：

+ `n_sample (int)`：采样的区域。

+ `pos_ratio (float)`：被标记为前景的区域比例。

+ `pos_iou_threshold (float)`： 最大IoU高于此阈值的区域被认为是前景。

+ `neg_iou_threshold_high`, `neg_iou_threshold_low`：

  最大IoU在`[neg_iou_threshold_low, neg_iou_threshold_high)`之间的区域被认为是背景。



**算法**：

**输入**：

+ `roi (numpy.ndarray)`：RPN生成的候选区域，形状`(R, 4)`，[x1, y1, x2, y2]，原图大小的。
+ `bbox (numpy.ndarray)`：图片的bounding box， 形状`(R', 4)`，[x1, y1, x2, y2]。
+ `label (numpy.ndarray)`：bounding box的类别标签，形状`(R',)`，数据范围`[0, L - 1]`，其中`L`是前景类别数量。
+ `loc_normalize_mean， loc_normalize_std`： 对生成的目标`gt_roi_loc`进行正则化。

**输出**：

+ `sample_roi (numpy.ndarray)`：采样的RoI， 形状`(S, 4)`，[x1, y1, x2, y2]。
+ `gt_roi_loc (numpy.ndarray)`： 将采样的RoI和ground truth bounding nox匹配的偏移和缩放， 形状 `(S, 4)`， [tx, ty, tw, th]。
+ `gt_roi_label (numpy.ndarray)`：采样的RoI的标签，形状`(S, )`，数据范围$[0, L]$，标签为0代表背景。

**算法流程**：

1. 将roi和bbox合并，形成新的roi。 ==持怀疑态度。==

2. 计算roi和bbox的iou，计算每个roi的最大IoU即对应的bbox，获取roi的标签`gt_roi_label`并+1，因为0是作为背景的类别。

3. 选出IoU大于`pos_iou_threshold`的RoI，获取本张图片的前景区域数量，`min(pos_roi_per_image, pos_index.shape[0])`，在这些RoI中随机选择作为前景区域。

   > `pos_roi_per_image = self.n_sample * self.pos_ratio`.
   >
   > `pos_index = np.where(max_iou >= self.pos_iou_threshold)[0]`

4. 选择`IoU`在`neg_iou_threshold_low, neg_iou_threshold_high`之间的ROI作为背景区域，同理，随机去除多余的区域(随机选取一部分区域)。

5. 合并前景RoI、背景RoI的索引(`pos_index, neg_index`)为`keep_index`，保留对应的标签`gt_roi_label = gt_roi_label[keep_index]`，并将其中背景部分标注为0; 保留对应的RoI， 即`sample_roi = roi[keep_index]`。

6. 计算采样的RoI匹配到对应ground truth bounding box的偏移和缩放`gt_roi_loc`。

7. 正则化`gt_roi_loc`。

8. 返回`sample_roi, gt_roi_loc, gt_roi_label`。

