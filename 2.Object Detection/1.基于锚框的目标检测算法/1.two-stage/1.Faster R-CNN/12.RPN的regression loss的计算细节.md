# RPN的regression loss的计算细节

Faster R-CNN的regression loss公式：
$$
\frac{1}{N_{reg}}\sum_{i}p_i^*L_{reg}(t_i, t_i^*)
$$
如果anchor为正，ground truth label $p_i^* = 1$，如果anchor为负，ground truth label $p_i^*=0$。

$t_i$代表预测边框的4个参数化坐标，$t_i^*$是和正anchor相关的ground truth box的参数化坐标。
$$
L_{reg}(t_i,t_i^*)=R(t_i-t_i^*)
$$
R代表robust loss 函数，这里使用的是smooth l1 loss，不过有所不同，因为标签中还有-1的，这一步需要筛选出参与计算regression loss的anchor，然后计算出smooth l1 loss (相当于reduction = "sum")后除以label = 0, label = 1的anchor个数。



```python
def _smooth_l1_loss(x: Tensor, t: Tensor, in_weight: Tensor):
    """
    Calculate the smooth l1 loss.
    """
    diff = in_weight * (x - t)
    abs_diff = diff.abs()
    flag = (abs_diff.data < 1.0).float()
    y = (flag * 0.5 * (diff ** 2)) + (1 - flag) * (abs_diff - 0.5)
    return y.sum()


def cal_loc_loss(pred_loc: Tensor, gt_loc: Tensor, gt_label: Tensor):
    """ Calculate the regression loss of RPN.

    Args:
        :@ predict_loc (Tensor[A, 4]): The predicted parameterized coordinates\
            of anchors.
        :@ gt_loc (Tensor[A, 4]): The target parameterized coordinates of anchors.
        :@ gt_label (Tensor[A]): The target labels of anchors.

    Returns:
        torch.float
        The smooth_l1_loss of location.
    """

    # TODO: add device
    in_weight = torch.zeros(gt_loc.shape)
    in_weight[(gt_label == 1).expand_as(in_weight)] = 1
    loc_loss = _smooth_l1_loss(pred_loc, gt_loc, in_weight.detach())
    loc_loss /= ((gt_label >= 0).sum().float())
    return loc_loss
```

